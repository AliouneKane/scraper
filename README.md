# Pulse.AI : Votre Boussole dans l'OcÃ©an de l'IA (SaaS)

**Pulse.AI** est votre plateforme de veille stratÃ©gique automatisÃ©e proposÃ©e sous forme de Dashboard interactif. Accessible directement via un navigateur, cette solution clÃ© en main transforme la surveillance de l'Ã©cosystÃ¨me IA en une expÃ©rience fluide, centralisant les meilleures sources d'information sans aucun effort manuel de votre part.

## ğŸ¯ Objectif du Projet & ProblÃ©matique MÃ©tier RÃ©elle

Dans le secteur technologique en Ã©volution rapide de l'Intelligence Artificielle, le dÃ©fi n'est plus de trouver de l'information, mais de filtrer le bruit. Pulse.AI rÃ©pond Ã  la question suivante : **"Comment un professionnel peut-il rester Ã  la pointe de l'innovation IA sans y consacrer des heures de recherche quotidiennes ?"**

Le projet rÃ©sout trois problÃ©matiques critiques :

1. **Fragmentation de l'Information** : Centraliser des sources dispersÃ©es (Substack, Beehiiv, Blogs) en un point d'accÃ¨s unique.
2. **Surcharge Cognitive** : Offrir une interface Ã©purÃ©e et premium qui privilÃ©gie la lisibilitÃ© et l'accÃ¨s rapide aux rÃ©sumÃ©s ("Insights").
3. **Obsolescence Rapide** : Mettre Ã  jour les donnÃ©es en temps rÃ©el grÃ¢ce Ã  des pipelines de scraping automatisÃ©s pour ne manquer aucune avancÃ©e majeure.

---

## ğŸ’» Stack des Langages de Programmation

* **Python** : UtilisÃ© pour le moteur de scraping, l'extraction de donnÃ©es et le nettoyage des flux (BeautifulSoup, Playwright, Requests).
* **TypeScript / JavaScript** : Choisi pour dÃ©velopper une interface utilisateur moderne avec **Next.js**, garantissant une application web rÃ©active et typÃ©e.
* **YAML** : UtilisÃ© pour la configuration de l'automatisation via **GitHub Actions**.

## ğŸ›  Stack Logicielle (Environnement & Outils)

* **Framework Frontend** : **Next.js 15+** associÃ© Ã  **Tailwind CSS v4** et **Shadcn UI** pour crÃ©er un Dashboard professionnel, fluide et animÃ©.
* **Moteur de Scraping** : **Playwright** & **BeautifulSoup4** pour naviguer et extraire les donnÃ©es des plateformes modernes (Substack, Beehiiv).
* **Automatisation (CI/CD)** : **GitHub Actions** configurÃ© pour un dÃ©clenchement quotidien (Cron job) Ã  07:00 UTC.
* **Design System** : Utilisation de composants premium (Glassmorphism, Marquee infini, Cartes interactives) inspirÃ©s par **21st.dev**.
* **Gestion de DonnÃ©es** : Stockage lÃ©ger en JSON pour une portabilitÃ© maximale et un dÃ©ploiement instantanÃ©.

## ğŸ§  Notions & Concepts ClÃ©s

La rÃ©alisation de ce projet fait intervenir des concepts avancÃ©s en ingÃ©nierie web et automatisation :

1. **Scraping Ã‰thique & Robuste** : Extraction ciblÃ©e de mÃ©tadonnÃ©es en respectant les structures HTML complexes.
2. **Veille AutomatisÃ©e (Cron Job)** : DÃ©ploiement d'un workflow GitHub Actions qui remplace les services payants comme Modal pour une exÃ©cution 100% gratuite.
3. **Modern UI/UX** :
    * **Glassmorphism** : Effets de transparence et de flou.
    * **Micro-interactions** : Animations fluides au survol.
4. **Pipeline d'IntÃ©gration Continue** : Synchronisation automatique des donnÃ©es rÃ©cupÃ©rÃ©es vers le dossier `public/` pour un rafraÃ®chissement immÃ©diat du site.

## ğŸ“‚ Architecture Dossier ComplÃ¨te

```text
scraper/ (Pulse.AI)
â”‚
â”œâ”€â”€ .github/workflows/              # Automatisation Cloud
â”‚   â””â”€â”€ daily_sync.yml              # Workflow GitHub Actions (Sync Ã  07h00)
â”‚
â”œâ”€â”€ tools/                          # Moteur d'Extraction (Backend Logic)
â”‚   â”œâ”€â”€ scraper.py                  # Script principal de scraping (BeautifulSoup)
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ src/                            # Interface Utilisateur (Frontend Next.js)
â”‚   â”œâ”€â”€ app/                        # Routing & Styles
â”‚   â”œâ”€â”€ components/                 # Composants visuels premium
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ public/                         # Ressources Statiques
â”‚   â””â”€â”€ articles.json               # Flux d'actualitÃ©s (Mis Ã  jour par l'IA)
â”‚
â”œâ”€â”€ run_sync.sh                     # Script de synchronisation locale
â”œâ”€â”€ requirements.txt                # DÃ©pendances Python (Playwright, BS4)
â”œâ”€â”€ package.json                    # DÃ©pendances Node.js
â””â”€â”€ README.md                       # Vision SaaS et Documentation
```

---

## ğŸš€ Comment reproduire le travail

### 1ï¸âƒ£ PrÃ©requis

* **Node.js** (v18+) et **Python 3.9+**.
* Un compte **GitHub** pour l'automatisation.

### 2ï¸âƒ£ Installation & Test Local

```bash
# Installation Frontend
npm install

# Installation Backend
pip install -r requirements.txt
playwright install chromium

# Lancement manuel du sync
./run_sync.sh

# Lancement du Dashboard
npm run dev
```

### 3ï¸âƒ£ Mise en place de l'Automatisation (GitHub Actions)

Le projet est dÃ©jÃ  configurÃ© pour tourner chaque matin Ã  **07:00 UTC**. Pour que cela fonctionne sur votre propre fork/repo :

1. Assurez-vous que les **"Actions"** sont activÃ©es dans les paramÃ¨tres de votre repo.
2. Le workflow `daily_sync.yml` s'occupera d'installer Playwright, de scraper les news et de push le fichier `articles.json` automatiquement.

---

## ğŸ§‘ğŸ’» Ã€ propos de l'auteur

<table style="border: none;">
<tr>
<td style="border: none;">
<strong>Alioune Abdou Salam Kane</strong>

<em>Ã‰lÃ¨ve IngÃ©nieur Statisticien Ã‰conomiste en 4e annÃ©e</em>

PassionnÃ© par l'IA/ML Engineering, la Data Science et le dÃ©veloppement de solutions SaaS innovantes.
</td>
</tr>
</table>

ğŸ‘‰ **Retrouvez mes autres projets :** [github.com/AliouneKane](https://github.com/AliouneKane)

---
